#服务器B(192.168.116.11)
b1.sources = r2
b1.sinks = k1 k2
b1.channels = c1 c2

# 将三者串联
b1.sources.r2.channels = c1 c2
b1.sinks.k1.channel = c1
b1.sinks.k2.channel = c2

# channel1
b1.channels.c1.type = memory
b1.channels.c1.capacity=30000
b1.channels.c1.transactionCapacity=1000

# channel2
b1.channels.c2.type=memory
b1.channels.c2.capacity=30000
b1.channels.c2.transactionCapacity=1000

# 配置监控文件
b1.sources.r2.type = avro
b1.sources.r2.bind=hadoop101
b1.sources.r2.port = 12345
b1.sources.r2.interceptors=i1 i2
b1.sources.r2.interceptors.i1.type=regex_filter
b1.sources.r2.interceptors.i1.regex=\\{.*\\}
b1.sources.r2.interceptors.i2.type=timestamp
#b1.sources.r2.interceptors = i1
#b1.sources.r2.interceptors.i1.type = timestamp
# k1
b1.sinks.k1.type=hdfs
b1.sinks.k1.channel=c1
b1.sinks.k1.hdfs.path=hdfs://hadoop102/user/hive/warehouse/profile.db/user_action/%Y-%m-%d
b1.sinks.k1.hdfs.useLocalTimeStamp = true
b1.sinks.k1.hdfs.fileType=DataStream
b1.sinks.k1.hdfs.writeFormat=Text
b1.sinks.k1.hdfs.rollInterval=0
b1.sinks.k1.hdfs.rollSize=10240
b1.sinks.k1.hdfs.rollCount=0
b1.sinks.k1.hdfs.idleTimeout=60
# k2
b1.sinks.k2.channel=c2
b1.sinks.k2.type=org.apache.flume.sink.kafka.KafkaSink
b1.sinks.k2.kafka.bootstrap.servers=hadoop103:9092
b1.sinks.k2.kafka.topic=click-trace
b1.sinks.k2.kafka.batchSize=20
b1.sinks.k2.kafka.producer.requiredAcks=1

